<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
    <meta name="description" content="A Dataset and Remote Sensing Benchmark for Multimodal Cloud Removal" />
    <meta name="author" content="Patrick Ebel" />
    <!--[if IE]>
        <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
        <![endif]-->
    <title>SEN12MS-CR Dataset</title>
    <!-- BOOTSTRAP CORE STYLE CSS -->
    <link href="../assets/css/bootstrap.css" rel="stylesheet" />
    <!-- Font-Awesome Icons Styles -->
    <link href="../assets/css/font-awesome.css" rel="stylesheet" />
     <!-- Pretty Photo For PopUp Styles -->
    <link href="../assets/css/prettyPhoto.css" rel="stylesheet" />
    <!-- CUSTOM STYLE CSS -->
    <link href="../assets/css/custom.css" rel="stylesheet" />    
    <!-- GOOGLE FONT -->
    <link href='http://fonts.googleapis.com/css?family=Open+Sans' rel='stylesheet' type='text/css' />
<style>

</style>

</head>
<body>
	<!-- insert MathJax to render LaTeX code via js -->
	<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
	<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
		 <section id="home-sec">
 		 <div class="imgandtextbanner">
		 	<img src="../assets/img/banners/ROIs2017_103/banner.gif" alt="cloudy_banner" style="width:80%; height:800px;">
		  	<div class="centeredtextblock">
				<h1>SEN12MS-CR DATASET</h1> 
				<h4>A Dataset and Remote Sensing Benchmark <br> 
					for Multimodal Cloud Removal</h4>
		  	</div>
		</div> 
		   
		 </section>

    <!-- HOME/VEDIO SECTION END-->
	<br />
<br />
<br />
<br />
       <section id="Introduction-sec"  >

           
            <div class="container basic-set" >
                <div class="row text-center">
                    <div class="col-md-12">
                        <h3 class="head-line"><span ></span>   Introduction <span > </span> </h3>
                        
                    </div>
                </div>
              <p class="lfs96-p">
              		On average, over half of all optical observations acquired via spaceborne Earth imagery are affected by clouds. As cloud coverage severely impedes the ongoing observation of Earth, the automated reconstruction of noisy or cloud covered information is a persistent problem in signal processing and remote sensing. While classical remote sensing applications oftentimes focused on narrowly-defined areals and case studies, the increasing availability of public-access, daily and large-scale satellite monitoring shifted the community's interest towards globally applicable methodology. To support the development of modern machine learning techniques for the purpose of cloud removal on whole-planet satellite data, we curated a large data set for training and evaluating new approaches.
				</p>  <br />
				<p class="lfs96-p">
This data set, SEN12MS-CR, is a multi-modal and mono-temporal data set for cloud removal. It contains paired and co-registered space-borne radar measurements practically unaffected by clouds, as well as cloud-covered and cloud-free multi-spectral optical satellite observations. The radar and optical data are collected via Sentinel-1 and Sentinel-2 satellites from European Space Agency's Copernicus mission, respectively. The Sentinel satellites provide public access data and are among the most prominent satellites in Earth observation. 
				</p>  <br />
				<p class="lfs96-p">
SEN12MS-CR is the first public data set for cloud removal in Earth observation to provide a large-scale global and all-season coverage. Based on the observation that cloud coverage varies widely in practice, all scenarios ranging from clear skies to absolute coverage are contained in the train and test data. By making this curated and readily pre-processed data set available to the research community, we hope to hope to help advance automated cloud removal in optical satellite data.
                  </p>
                  <br />
			
           <figure class="item">
            	<img src="../assets/img/samples/mono/sample_mono.png" class="img-responsive " alt="" width="800px" style="margin:auto;"/>
                <figcaption class="caption"><small>Exemplary triplets of data. Every sample in SEN12MS-CR is a tuple consisting of 2-bands Sentinel-1 radar measurements, as well as cloudy and cloud-free 13-bands Sentinel-2 optical observations.</small></figcaption>
		   </figure>
		   
           </div>
           </section>
		   	<br />
			<br />
			<br />
			<br />

		   <section id="Statistics-sec"  >
           
            <div class="container basic-set" >
                <div class="row text-center">
                    <div class="col-md-12">
                        <h3 class="head-line"><span ></span>   Statistics <span > </span> </h3>
                        
                    </div>
                </div>
					  <p class="lfs96-p">
                      SEN12MS-CR is a global data set for multi-modal cloud removal. It contains observations covering 175 globally distributed Regions of Interest recorded in one of four seasons throughout the year of 2018. For each region, synthetic aperture radar (SAR) Sentinel-1 as well as cloudy and cloud-free optical multi-spectral Sentinel-2 are provided. The full-scene images are sliced up into a total of 122,218 patch triplets, each patch of size \(256 \times 256 \: px^2\). The samples are patch-wise co-registered and fully compatible with the <a href="https://github.com/schmitt-muc/SEN12MS"; target="_blank">SEN12MS data set</a>, such that semantic segmentation and scene classification can be performed based on the available semantic land cover annotations. The approximate cloud coverage of all data is about at circa 48%---reaching from clear-view images (e.g. for validation purposes), over semi-transparent haze or small clouds to dense and wide cloud coverage.
                  </p>
            <figure class="item">
            	<img src="../assets/img/maps/SEN12MS_atlas.png" class="img-responsive " alt="" width="900px" style="margin:auto;"/>
                <figcaption class="caption"><small>Geospatial distribution of ROI in SEN12MS-CR. Different colors indicate differences in seasons collected.</small></figcaption>
			</figure>
           </div>
           </section>
		   <br />

           <figure class="item">
            	<img src="../assets/img/monotemp_full_scene.png" class="img-responsive " alt="" width="1000px" style="margin:auto;"/>
                <figcaption class="caption"><small>Exemplary cloud removal results. Left to right: Radar data, loud-covered optical data, cloud-removed optical predictions and cloud-free reference optical data.</small></figcaption>
		   </figure>
		   
<br />
<br />
<br />

<p style="text-align:center;"><span style="text-decoration:underline">Benchmarking</span></p>

<style type="text/css">
.tg  {border-collapse:collapse;border-spacing:0;}
.tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  overflow:hidden;padding:8px 20px;word-break:normal;}
.tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  font-weight:normal;overflow:hidden;padding:8px 20px;word-break:normal;}
.tg .tg-z4i2{border-color:#000000;text-align:left;vertical-align:middle}
.tg .tg-km2t{border-color:#000000;font-weight:bold;text-align:left;vertical-align:top}
.tg .tg-zv4m{border-color:#000000;text-align:left;vertical-align:top}
</style>
<table class="tg">
<thead>
  <tr>
    <th class="tg-z4i2">Method</th>
    <th class="tg-z4i2">MAE &#8595</th>
    <th class="tg-z4i2">SAM &#8595</th>
    <th class="tg-z4i2">PSNR &#8593</th>
    <th class="tg-z4i2">SSIM &#8593</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td class="tg-zv4m">McGAN <a href="https://openaccess.thecvf.com/content_cvpr_2017_workshops/w18/html/Enomoto_Filmy_Cloud_Removal_CVPR_2017_paper.html"; target="_blank">(Enomoto et al., 2017)</a></td>
    <td class="tg-zv4m">0.048</td>
    <td class="tg-zv4m">15.676</td>
    <td class="tg-zv4m">25.14</td>
    <td class="tg-zv4m">0.744</td>
  </tr>
  <tr>
    <td class="tg-zv4m">SAR-Opt-cGAN <a href="https://ieeexplore.ieee.org/document/8519215"; target="_blank">(Grohnfeldt et al., 2018)</a></td>
    <td class="tg-zv4m">0.043</td>
    <td class="tg-zv4m">15.494</td>
    <td class="tg-zv4m">25.59</td>
    <td class="tg-zv4m">0.764</td>
  </tr>
  <tr>
    <td class="tg-zv4m"><span style="font-weight:400;font-style:normal">SAR2OPT <a href="https://www.isprs-ann-photogramm-remote-sens-spatial-inf-sci.net/IV-1/5/2018/"; target="_blank">(Bermudez et al., 2018)</a></span></td>
    <td class="tg-zv4m">0.042</td>
    <td class="tg-zv4m">14.788</td>
    <td class="tg-zv4m">25.87</td>
    <td class="tg-zv4m">0.793</td>
  </tr>
  <tr>
    <td class="tg-zv4m">SpA GAN <a href="https://arxiv.org/abs/2009.13015"; target="_blank">(Pan, 2020)</a></td>
    <td class="tg-zv4m">0.045</td>
    <td class="tg-zv4m">18.085</td>
    <td class="tg-zv4m">24.78</td>
    <td class="tg-zv4m">0.754</td>
  </tr>
  <tr>
    <td class="tg-zv4m">Simulation-Fusion GAN <a href="https://www.mdpi.com/2072-4292/12/1/191"; target="_blank">(Gao et al., 2020)</a></td>
    <td class="tg-zv4m">0.045</td>
    <td class="tg-zv4m">16.633</td>
    <td class="tg-zv4m">24.73</td>
    <td class="tg-zv4m">0.701</td>
  </tr>
  <tr>
    <td class="tg-zv4m">DSen2-CR <a href="https://www.sciencedirect.com/science/article/pii/S0924271620301398"; target="_blank">(Meraner et al., 2020)</a></td>
    <td class="tg-zv4m">0.031</td>
    <td class="tg-zv4m">9.472</td>
    <td class="tg-zv4m">27.76</td>
    <td class="tg-zv4m">0.874</td>
  </tr>
  <tr>
    <td class="tg-zv4m">GLF-CR <a href="https://www.sciencedirect.com/science/article/pii/S0924271622002064"; target="_blank">(Xu et al., 2022)</a></td>
    <td class="tg-zv4m">0.028</td>
    <td class="tg-zv4m">8.981</td>
    <td class="tg-zv4m">28.64</td>
    <td class="tg-km2t">0.885</td>
  </tr>
  <tr>
    <td class="tg-zv4m">UnCRtainTS L2 <a href="https://arxiv.org/abs/2304.05464"; target="_blank">(Ebel et al., 2023)</a></td>
    <td class="tg-km2t">0.027</td>
    <td class="tg-km2t">8.320</td>
    <td class="tg-km2t">28.90</td>
    <td class="tg-zv4m">0.880</td>
  </tr>
</tbody>
</table>

<br /> 
<p style="text-align:center;">
Feel free to report this benchmarking of prior methods in your work utilizing SEN12MS-CR. 
<br /> 
Please reach out to us if you would like to have your work referenced and your model included in the benchmark.
</p>

<br />
<br />
<br />
<br />
		   <section id="Download-sec"  >

           
            <div class="container basic-set" >
                <div class="row text-center">
                    <div class="col-md-12">

                        <h3 class="head-line"><span ></span>   Download <span > </span> </h3>
                        
                    </div>
                </div>
		    <div class="txt-block">

									<p style="width:1000px;">
											1. Dataset
										
									</p>
			    <p style="text-align:center;">
                            Download Link <a href="https://mediatum.ub.tum.de/1554803"; target="_blank">here</a> and <a href="https://u.pcloud.link/publink/show?code=kZ46bk0Z5JKM8r2bzfyjYl3dW85U60XaBmPV"; target="_blank">here (supplementary, e.g. splits)</a><br/><br/>
                Note: You can also download (parts of) the data in the terminal (passwd: m1554803) using wget or rsync, for instance via <br/>
                
               	<code>
           			wget "ftp://m1554803:m1554803@dataserv.ub.tum.de/ROIs1158_spring_s1.tar.gz" 
				</code><br/>
               	<code>
				rsync -chavzP --stats rsync://m1554803@dataserv.ub.tum.de/m1554803/ .
				</code><br/><br/>
				</p>
				<p style="text-align:center;">
				 <b>Update: </b> You can now easily get the dataset via this automated downloading script <a href="https://github.com/PatrickTUM/SEN12MS-CR-TS/blob/master/util/dl_data.sh"; target="_blank">here</a>.
				</p>
                  
        </div>
        		    <div class="txt-block">

									<p style="width:1000px;">
											2. Code
										
									</p>
			    <p style="text-align:center;">
                            Download Links <a href="https://github.com/PatrickTUM/SEN12MS-CR-TS"; target="_blank">here</a> and <a href="https://github.com/ameraner/dsen2-cr"; target="_blank">here</a>
                </p>
                  
        </div>
        
				<div class="txt-block">

									<p style="width:1000px;">
											3. Trained Models
									</p>
                  
        </div>


        
<p style="text-align:center;">
                            Cloud Removal Models
                  </p>
<table class="tg">
<thead>
  <tr>
    <th class="tg-804w">Model</th>
    <th class="tg-804w">Weights Download</th>
    <th class="tg-804w">Description</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td class="tg-804w">DSen2-CR</td>
    <td class="tg-804w"><a href="https://drive.google.com/file/d/1L3YUVOnlg67H5VwlgYO9uC9iuNlq7VMg/view?usp=sharing"; title="large ResNet"; target="_blank">GoogleDrive</a> </br><a href="https://u.pcloud.link/publink/show?code=XZD6bk0Zjkq1tI2qPjbCAa7gKDJ1ObwmWsBV"; title="large ResNet"; target="_blank">pCloud Share</a></td>
    <td class="tg-804w">[Tensorflow] The network trained on SEN12MS-CR in <i>Meraner et al 2020</i> on paired radar and cloudy optical satellite observations.</td>
  </tr>
  <tr>
    <td class="tg-804w">ResNet</td>
    <td class="tg-804w"><a href="https://u.pcloud.link/publink/show?code=XZx6bk0ZTAa8d52TH7HpDBBN5tBUXhOfkC0X"; title="small ResNet"; target="_blank">pCloud Share</a><br></td>
    <td class="tg-804w">[PyTorch] A ResNet16 pre-trained for mono-temporal cloud removal on <a href=#"; target="_blank">SEN12MS-CR</a>. Takes radar and multi-spectral satellite data as inputs to make cloud-removed multispectral optical predictions.</td>
  </tr>
  <tr>
    <td class="tg-zda1">GLF-CR</td>
    <td class="tg-zda1"><a href="https://drive.google.com/file/d/11EYrrqLzlqrDgrJNgIW7IY0nSz_S5y9Z/view?usp=sharing"; target="_blank">Google Drive</a></td>
    <td class="tg-zda2">[PyTorch] The vision transformer cloud removal network trained on SEN12MS-CR in <i>Xu et al 2022</i> on  paired radar and cloudy optical satellite observations. Code <a href="https://github.com/xufangchn/GLF-CR"; target="_blank">here</a>.</td>
  </tr>
  <tr>
    <td class="tg-zda1">UnCRtainTS (t=1)</td>
    <td class="tg-zda1"><a href="https://u.pcloud.link/publink/show?code=kZYIbk0ZBSU3dvlJRRhwPmraR922E5MRzlpX"; target="_blank">pCloud Share</a></td>
    <td class="tg-zda2">[PyTorch] The monotemporal version of the uncertainty prediction network trained on SEN12MS-CR in <i>Ebel et al 2023</i> on  paired radar and cloudy optical satellite observations. Code <a href="https://github.com/PatrickTUM/UnCRtainTS"; target="_blank">here</a>.</td>
  </tr>
  <tr>
  </tr>
</tbody>
</table>
<br>
</div>
</section>

<br />
<br />
<br />
<br />

<section id="References-sec"  >
           
    <div class="container basic-set" >
        <div class="row text-center">
            <div class="col-md-12">
                <h3 class="head-line"><span ></span>   References <span > </span> </h3>    
            </div>
        </div>
              
  		<div class="txt-block">
			<p style="max-width:1000px;">
					1. Citation <br> <br>
					&nbsp &nbsp If you utilize this dataset in your work, please use the following citation:
			</p>
			<p id = "rcorners2">
			<small>
				@article{sen12mscr,<br>
						 &nbsp &nbsp &nbsp &nbsp title = {{Multisensor Data Fusion for Cloud Removal in Global and All-Season Sentinel-2 Imagery}},<br>
						 &nbsp &nbsp &nbsp &nbsp author = {Ebel, Patrick and Meraner, Andrea and Schmitt, Michael and Zhu, Xiao Xiang},<br>
						 &nbsp &nbsp &nbsp &nbsp journal = {IEEE Transactions on Geoscience and Remote Sensing},<br>
						 &nbsp &nbsp &nbsp &nbsp year = {2020}<br>
						 &nbsp &nbsp &nbsp &nbsp publisher = {IEEE}<br>
				}
			</small>
			</p>
        </div>
   </div>
</section>

           
           <figure class="item">
           <img src="../assets/img/logos/unibw_logo.png" style="float: right; width: 7%; margin-right: 1%; margin-bottom: 0.5em;"> 
           <img src="../assets/img/logos/DLR_Logo.svg" style="float: right; width: 10%; margin-right: 1%; margin-bottom: 0.5em;">
           <img src="../assets/img/logos/Logo_of_the_Technical_University_of_Munich.svg" style="float: right; width: 15%; margin-right: 1%; margin-bottom: 0.5em;">


         <p style="position: float; bottom: 0px; left: 0px; width: 250px;">
         <br ><br ><br ><br ><br >
           © Patrick Ebel <a href="https://pwjebel.com"; target="_blank">www.pwjebel.com</a>.
         </p>    
         		   
       <!-- CONTACT  SECTION END-->

    <!-- JAVASCRIPT FILES PLACED AT THE BOTTOM TO REDUCE THE LOADING TIME  -->
    <!-- BOOTSTRAP SCRIPTS  -->
    <script src="../assets/js/bootstrap.js"></script>
     <!-- EASING SCROLL SCRIPTS PLUGIN  -->
    <script src="../assets/js/custom.js"></script>
    
</body>
</html>
